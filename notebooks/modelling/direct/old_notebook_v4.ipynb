{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "import numpy as np\n",
    "from sktime.forecasting.arima import ARIMA\n",
    "from sktime.forecasting.compose import TransformedTargetForecaster, DirectTimeSeriesRegressionForecaster, DirectTabularRegressionForecaster\n",
    "from sktime.transformations.series.detrend import Deseasonalizer\n",
    "from sktime.forecasting.trend import PolynomialTrendForecaster\n",
    "from sktime.transformations.series.detrend import Detrender\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sktime.forecasting.compose import make_reduction\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import requests\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sktime.forecasting.model_selection import SlidingWindowSplitter\n",
    "from sktime.forecasting.compose import YfromX\n",
    "from sktime.transformations.series.boxcox import LogTransformer\n",
    "from sktime.transformations.compose import ColumnwiseTransformer\n",
    "from sktime.forecasting.compose import ForecastingPipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct Strategy V3\n",
    "Adding more lags to the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "import numpy as np\n",
    "from sktime.forecasting.arima import ARIMA\n",
    "from sktime.forecasting.compose import (\n",
    "    TransformedTargetForecaster,\n",
    "    DirectTimeSeriesRegressionForecaster,\n",
    "    DirectTabularRegressionForecaster,\n",
    ")\n",
    "from sktime.transformations.series.detrend import Deseasonalizer\n",
    "from sktime.forecasting.trend import PolynomialTrendForecaster\n",
    "from sktime.transformations.series.detrend import Detrender\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sktime.forecasting.compose import make_reduction\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import requests\n",
    "from sklearn.ensemble import (\n",
    "    HistGradientBoostingRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    ")\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sktime.forecasting.model_selection import SlidingWindowSplitter\n",
    "from sktime.forecasting.compose import YfromX\n",
    "from sktime.transformations.series.boxcox import LogTransformer\n",
    "from sktime.transformations.compose import ColumnwiseTransformer\n",
    "from sktime.forecasting.compose import ForecastingPipeline\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import my_reduce\n",
    "import my_pipelinee\n",
    "\n",
    "class TimeSeriesForecasting:\n",
    "    def __init__(\n",
    "        self,\n",
    "        len_models=12,\n",
    "        num_lags=24,\n",
    "    ):\n",
    "        self.len_models = len_models\n",
    "        self.num_lags = num_lags\n",
    "        self.models = {}\n",
    "        self.X_sub_train = {}\n",
    "        self.forecast_len = 1\n",
    "        self.fh = ForecastingHorizon(np.arange(1, 2))\n",
    "        self.next_y_window = None\n",
    "        self.cutoff = None\n",
    "\n",
    "    def create_sliding_window_data_refined(self, ts, window_length):\n",
    "        splitter = SlidingWindowSplitter(\n",
    "            fh=[1], window_length=window_length, step_length=1\n",
    "        )\n",
    "        # Split the series using the splitter\n",
    "        split_series = list(splitter.split_series(ts))\n",
    "        # Create an empty DataFrame to store the data\n",
    "        data = pd.DataFrame()\n",
    "        # Iterate over the split series and extract the features and target\n",
    "        for i, (train, test) in enumerate(split_series):\n",
    "            # Extract features and target from the split series\n",
    "            features = ts[train.index]\n",
    "            target = ts[test.index]\n",
    "            split_data = {\"date\": pd.to_datetime(target.index[0].to_pydatetime())}\n",
    "\n",
    "            for i, j in zip(range(window_length, 0, -1), range(0, window_length)):\n",
    "                split_data[f\"lag_{i}\"] = features[j]\n",
    "\n",
    "            split_data[f\"target\"] = target[0]\n",
    "\n",
    "            split_df = pd.DataFrame(split_data, index=[\"date\"])\n",
    "\n",
    "            data = pd.concat([data, split_df])\n",
    "        data.set_index(\"date\", inplace=True)\n",
    "        return data\n",
    "\n",
    "    def fit(self, y, X):\n",
    "        X_transformed, y_transformed = self.transform(y, X)\n",
    "\n",
    "        for j in range(1, self.len_models + 1):\n",
    "            model_name = f\"model_{j}\"\n",
    "            X_train_name = f\"X_train_{j}\"\n",
    "\n",
    "            lag_cols = [f\"lag_{i}\" for i in range(j, j + self.num_lags)]\n",
    "\n",
    "            self.X_sub_train[X_train_name] = X_transformed[\n",
    "                lag_cols + self.selected_cols\n",
    "            ].copy()\n",
    "\n",
    "            self.X_sub_train[X_train_name] = self.X_sub_train[X_train_name].asfreq(\"H\")\n",
    "\n",
    "            self.models[model_name] = YfromX(\n",
    "                                        RandomForestRegressor(\n",
    "                                            n_estimators=200, n_jobs=-1\n",
    "                                        )\n",
    "                                    )\n",
    "\n",
    "            self.models[model_name].fit(\n",
    "                y=y_transformed, X=self.X_sub_train[X_train_name], fh=self.fh\n",
    "            )\n",
    "\n",
    "        self.cutoff = self.models[\"model_1\"].cutoff\n",
    "\n",
    "    def transform(self, y, X):\n",
    "        len_models = self.len_models\n",
    "        num_lags = self.num_lags\n",
    "\n",
    "        window_length = num_lags + len_models - 1\n",
    "\n",
    "        data_df = TimeSeriesForecasting().create_sliding_window_data_refined(\n",
    "            y, window_length\n",
    "        )\n",
    "\n",
    "        data_df = pd.merge(data_df, X, left_index=True, right_index=True)\n",
    "\n",
    "        x_feature_names = [f\"lag_{i}\" for i in range(1, window_length + 1)]\n",
    "\n",
    "        last_row = data_df[x_feature_names].iloc[[-1]]\n",
    "        last_row = last_row.shift(1, axis=1)\n",
    "        last_row.iloc[:, 0] = data_df['target'].iloc[-1]\n",
    "\n",
    "        last_row.index = last_row.index + pd.Timedelta(hours=1)\n",
    "\n",
    "        self.next_y_window = last_row\n",
    "\n",
    "        self.selected_cols = X.columns.tolist()\n",
    "        x_feature_names += self.selected_cols\n",
    "\n",
    "        X_transformed = data_df[x_feature_names]\n",
    "        y_transformed = data_df[\"target\"]\n",
    "        return X_transformed,y_transformed\n",
    "\n",
    "    def predict(self, X):\n",
    "        # X passed here is features like ail alone\n",
    "        # Combine the last y window with the features\n",
    "\n",
    "        X = pd.concat([self.next_y_window, X], axis=1)\n",
    "        \n",
    "        predictions_df = pd.DataFrame()\n",
    "        \n",
    "        X_sub_test = {}\n",
    "        for j in range(1, self.len_models + 1):\n",
    "            model_name = f\"model_{j}\"\n",
    "            lag_cols = [f\"lag_{i}\" for i in range(j, j + self.num_lags)]\n",
    "            X_test_name = f\"X_test_{j}\"\n",
    "\n",
    "            X_sub_test[X_test_name] = X[lag_cols + self.selected_cols].copy()\n",
    "            X_sub_test[X_test_name] = X_sub_test[X_test_name].asfreq(\"H\")\n",
    "\n",
    "            cutoff_time = self.models[model_name].cutoff\n",
    "            prediction_for = cutoff_time + pd.DateOffset(hours=j)\n",
    "\n",
    "            y_pred = self.models[model_name].predict(\n",
    "                fh=self.fh, X=X_sub_test[X_test_name]\n",
    "            )\n",
    "\n",
    "            row = pd.DataFrame(\n",
    "                {f\"cutoff_hour_{self.models['model_1'].cutoff.hour[0]}\": y_pred[0]},\n",
    "                index=pd.Index(prediction_for),\n",
    "            )\n",
    "\n",
    "            predictions_df = predictions_df.append(row)\n",
    "            \n",
    "        predictions_df.index.name = \"date\"\n",
    "        return predictions_df\n",
    "\n",
    "    def update(self, new_observation_y, new_observation_X):\n",
    "\n",
    "        X = pd.concat([self.next_y_window, new_observation_X], axis=1)\n",
    "        \n",
    "        X_sub_test = {}\n",
    "        \n",
    "        for j in range(1, self.len_models + 1):\n",
    "            model_name = f\"model_{j}\"\n",
    "            X_test_name = f\"X_test_{j}\"\n",
    "            lag_cols = [f\"lag_{i}\" for i in range(j, j + self.num_lags)]\n",
    "\n",
    "            X_sub_test[X_test_name] = X[lag_cols + self.selected_cols].copy()\n",
    "            X_sub_test[X_test_name] = X_sub_test[X_test_name].asfreq(\"H\")\n",
    "            \n",
    "            new_observation_y = new_observation_y.asfreq(\"H\")\n",
    "\n",
    "            self.models[model_name].update(\n",
    "                y=new_observation_y, X=X_sub_test[X_test_name], update_params=False\n",
    "            )\n",
    "        \n",
    "        # update the cutoff\n",
    "        self.cutoff = self.models[\"model_1\"].cutoff\n",
    "        \n",
    "        # Update the next y window\n",
    "        self.next_y_window = self.next_y_window.shift(1, axis=1)\n",
    "        self.next_y_window.iloc[:, 0] = new_observation_y.iloc[0]\n",
    "        self.next_y_window.index = self.next_y_window.index + pd.Timedelta(hours=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_old_df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/slalom-ubc-mds/Power-Price-Prediction/main/data/processed/supply_load_price.csv\",\n",
    "    parse_dates=[\"Date (MST)\"],\n",
    "    index_col=\"Date (MST)\",\n",
    ")\n",
    "\n",
    "price_old_df = price_old_df.asfreq(\"H\")\n",
    "price_old_df = price_old_df.sort_values(by=\"Date (MST)\")\n",
    "\n",
    "selected_cols = [\n",
    "    \"ail\",\n",
    "    \"gas_price\",\n",
    "    \"gas_reserve_margin\",\n",
    "    \"coal_reserve_margin\",\n",
    "    \"wind_reserve_margin\",\n",
    "    \"other_reserve_margin\",\n",
    "    \"gas_supply_mix\",\n",
    "    \"coal_supply_mix\",\n",
    "    \"wind_supply_mix\",\n",
    "    \"other_supply_mix\",\n",
    "    \"total_reserve_margin\",\n",
    "    \"demand_supply_ratio\",\n",
    "]\n",
    "price_old_df_filtered = price_old_df.loc[\n",
    "    \"2022-12-01\":\"2023-03-28\", selected_cols + [\"price\"]\n",
    "]\n",
    "y = price_old_df_filtered[\"price\"]\n",
    "y.name = \"target\"\n",
    "\n",
    "X = price_old_df_filtered[selected_cols]\n",
    "\n",
    "X = X.asfreq(\"H\")\n",
    "y = y.asfreq(\"H\")\n",
    "\n",
    "# test_size = 48\n",
    "# forcast_len = 1\n",
    "\n",
    "# total_forecast_len = 12\n",
    "\n",
    "# y_train, y_test_full, X_train, X_test = temporal_train_test_split(y, X, test_size=test_size+total_forecast_len)\n",
    "\n",
    "# y_test = y_test_full[:-total_forecast_len] # We need X for the last forcast_len hours to make predictions.\n",
    "\n",
    "# y_train = y_train.asfreq('H')\n",
    "# X_train = X_train.asfreq('H')\n",
    "# X_test = X_test.asfreq('H')\n",
    "# y_test = y_test.asfreq('H')\n",
    "\n",
    "# forecasting = TimeSeriesForecasting(\n",
    "#     len_models=12,\n",
    "#     num_lags=24,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds = 23\n"
     ]
    }
   ],
   "source": [
    "import my_functions\n",
    "from sktime.performance_metrics.forecasting import MeanSquaredScaledError, MeanSquaredError\n",
    "\n",
    "import my_functions\n",
    "from sktime.forecasting.model_selection import (\n",
    "    ExpandingWindowSplitter,\n",
    ")\n",
    "\n",
    "cv = ExpandingWindowSplitter(\n",
    "    initial_window=int(len(X) * 0.9), step_length=12, fh=np.arange(1, 13)\n",
    ")\n",
    "\n",
    "n_splits = cv.get_n_splits(y)\n",
    "print(f\"Number of Folds = {n_splits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_cv_results = []\n",
    "rmse_cv_std = []\n",
    "\n",
    "results = my_functions.evaluate(\n",
    "    forecaster=TimeSeriesForecasting,\n",
    "    y=y,\n",
    "    X=X,\n",
    "    cv=cv,\n",
    "    strategy=\"refit\",\n",
    "    return_data=True,\n",
    "    scoring=MeanSquaredError(square_root=True),\n",
    "    backend=\"loky\",\n",
    "    error_score='raise'\n",
    ")\n",
    "    \n",
    "rmse = results[\"test_MeanSquaredError\"].mean()\n",
    "rmse_std = results[\"test_MeanSquaredError\"].std()\n",
    "rmse_cv_results.append(rmse)\n",
    "rmse_cv_std.append(rmse_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE_CV</th>\n",
       "      <th>RMSE_CV_STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Direct</td>\n",
       "      <td>174.913185</td>\n",
       "      <td>122.402127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model     RMSE_CV  RMSE_CV_STD\n",
       "0  Direct  174.913185   122.402127"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_cv_results_df = pd.DataFrame(\n",
    "    {\"Model\": [\"Direct\"], \"RMSE_CV\": rmse_cv_results, \"RMSE_CV_STD\": rmse_cv_std}\n",
    ").sort_values(by=[\"RMSE_CV\"])\n",
    "rmse_cv_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39m1\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m0\u001b[39;49m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasting.fit(y=y_train, X=X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = forecasting.predict(X_test.iloc[[0]])\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_prediction_df = pd.DataFrame(index=y_test_full.index)\n",
    "rolling_prediction_df = pd.concat([rolling_prediction_df, predictions_df], axis=1)\n",
    "rolling_prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emulating the rolling prediction for the next hours\n",
    "\n",
    "for i in range(0, len(y_test)): # Loop through the test set emulating the passing by of one hour. \n",
    "        \n",
    "        predictions_df = pd.DataFrame()\n",
    "        predictions_df\n",
    "                \n",
    "        new_observation_y, new_observation_X  = y_test[i:i+1], X_test[i:i+1]\n",
    "\n",
    "        new_observation_y = new_observation_y.asfreq('H')\n",
    "        new_observation_X = new_observation_X.asfreq('H')\n",
    "\n",
    "        print(f'Cut off before update: {forecasting.models[\"model_1\"].cutoff}')\n",
    "\n",
    "        forecasting.update(y_test.iloc[[i]], X_test.iloc[[i]])\n",
    "\n",
    "        print(f'Cut off after update: {forecasting.models[\"model_1\"].cutoff}')\n",
    "\n",
    "        cutoff_time = forecasting.models[\"model_1\"].cutoff\n",
    "\n",
    "        prediction_for = cutoff_time + pd.DateOffset(hours=1)\n",
    "\n",
    "        print(f'Predicting for {prediction_for}')\n",
    "        \n",
    "        y_pred = forecasting.predict(X_test.iloc[[i+1]])\n",
    "\n",
    "        rolling_prediction_df = pd.concat([rolling_prediction_df, y_pred], axis=1)\n",
    "        \n",
    "        print(f'Update and prediction done for {new_observation_y.index[0]}')\n",
    "        print(f'----------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_step_predictions(rolling_prediction_df, y_test_full, num_steps):\n",
    "    step_predictions = []\n",
    "    \n",
    "    for step in range(0, num_steps):\n",
    "        diag_values = np.diag(rolling_prediction_df.values, -step)\n",
    "        \n",
    "        index_range = y_test_full.index[step:step + len(diag_values)]\n",
    "        column_name = f'{step+1}_step_prediction'\n",
    "        \n",
    "        prediction_df = pd.DataFrame(diag_values, index=index_range, columns=[column_name])\n",
    "        \n",
    "        if y_test_full[step:step + len(prediction_df)].index.equals(prediction_df.index):\n",
    "            step_predictions.append(prediction_df)\n",
    "        else:\n",
    "            print(f\"Error: Index mismatch for {step}-step prediction.\")\n",
    "    \n",
    "    return step_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = generate_step_predictions(rolling_prediction_df, y_test_full, total_forecast_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions[0] # 1 initial prediction + 48 steps of update and prediction from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions[1] # 1 initial prediction + 48 steps of update and prediction from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions[2] # 1 initial prediction + 48 steps of update and prediction from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_sizes = np.arange(1, 12+1)\n",
    "for step, prediction_series in zip(step_sizes, predictions):\n",
    "    if y_test_full[step-1:step+test_size].index.equals(prediction_series.index):\n",
    "        rmse = mean_squared_error(y_test_full[step-1:step+test_size], prediction_series, squared=False)\n",
    "        print(f\"{step} Step RMSE for model: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_cv_results_df = pd.DataFrame(\n",
    "    {\"Model\": ['direct'], \"RMSE_CV\": rmse_cv_results, \"RMSE_CV_STD\": rmse_cv_std}\n",
    ").sort_values(by=[\"RMSE_CV\"])\n",
    "rmse_cv_results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slalomenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
