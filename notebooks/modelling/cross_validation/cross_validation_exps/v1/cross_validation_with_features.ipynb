{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sktime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "import numpy as np\n",
    "from sktime.forecasting.arima import ARIMA\n",
    "from sktime.forecasting.compose import TransformedTargetForecaster\n",
    "from sktime.transformations.series.detrend import Deseasonalizer\n",
    "from sktime.forecasting.trend import PolynomialTrendForecaster\n",
    "from sktime.transformations.series.detrend import Detrender\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sktime.forecasting.compose import make_reduction\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import requests\n",
    "from sklearn.ensemble import (\n",
    "    HistGradientBoostingRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    ")\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sktime.forecasting.model_selection import (\n",
    "    ForecastingGridSearchCV,\n",
    "    ExpandingWindowSplitter,\n",
    ")\n",
    "from sktime.forecasting.compose import MultiplexForecaster\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sktime.forecasting.ets import AutoETS\n",
    "from sktime.transformations.series.boxcox import LogTransformer\n",
    "\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sktime.forecasting.compose import ForecastingPipeline\n",
    "from sktime.transformations.series.adapt import TabularToSeriesAdaptor\n",
    "\n",
    "\n",
    "def initialize_arima_forecaster():\n",
    "    pipe = ForecastingPipeline(\n",
    "        steps=[\n",
    "            (\"standardize\", TabularToSeriesAdaptor(StandardScaler())),\n",
    "            (\n",
    "                \"forecaster\",\n",
    "                TransformedTargetForecaster(\n",
    "                    [\n",
    "                        (\"log_transformer\", LogTransformer()),\n",
    "                        (\n",
    "                            \"deseasonalizer_daily\",\n",
    "                            Deseasonalizer(sp=24, model=\"additive\"),\n",
    "                        ),\n",
    "                        (\n",
    "                            \"deseasonalizer_weekly\",\n",
    "                            Deseasonalizer(sp=24 * 7, model=\"additive\"),\n",
    "                        ),\n",
    "                        (\"residual_forecaster\", ARIMA(1, 0, 1)),\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return pipe\n",
    "\n",
    "\n",
    "def initialize_elasticnet_forecaster():\n",
    "    deseasonalizer_weekly = Deseasonalizer(sp=24 * 7, model=\"additive\")\n",
    "    # Create the TransformedTargetForecaster pipeline\n",
    "    pipe = ForecastingPipeline(\n",
    "        steps=[\n",
    "            (\"standardize\", TabularToSeriesAdaptor(StandardScaler())),\n",
    "            (\n",
    "                \"forecaster\",\n",
    "                TransformedTargetForecaster(\n",
    "                    [\n",
    "                        (\"log_transformer\", LogTransformer()),\n",
    "                        # (\"deseasonalizer_weekly\", Deseasonalizer(sp=24*7, model=\"additive\")),\n",
    "                        (\n",
    "                            \"forecast\",\n",
    "                            make_reduction(\n",
    "                                ElasticNetCV(n_jobs=-1),\n",
    "                                window_length=24,\n",
    "                                strategy=\"direct\",\n",
    "                            ),\n",
    "                        ),\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return pipe\n",
    "\n",
    "\n",
    "def initialize_rf_forecaster():\n",
    "    # Create the TransformedTargetForecaster pipeline\n",
    "    pipe = ForecastingPipeline(\n",
    "        steps=[\n",
    "            (\"standardize\", TabularToSeriesAdaptor(StandardScaler())),\n",
    "            (\n",
    "                \"forecaster\",\n",
    "                TransformedTargetForecaster(\n",
    "                    [\n",
    "                        (\"log_transformer\", LogTransformer()),\n",
    "                        # (\"deseasonalizer_weekly\", Deseasonalizer(sp=24*7, model=\"additive\")),\n",
    "                        (\n",
    "                            \"forecast\",\n",
    "                            make_reduction(\n",
    "                                RandomForestRegressor(n_estimators=200, n_jobs=-1),\n",
    "                                window_length=24,\n",
    "                                strategy=\"direct\",\n",
    "                            ),\n",
    "                        ),\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return pipe\n",
    "\n",
    "\n",
    "def initialize_gb_forecaster():\n",
    "    deseasonalizer_daily = Deseasonalizer(sp=24, model=\"additive\")\n",
    "    pipe = ForecastingPipeline(\n",
    "        steps=[\n",
    "            (\"standardize\", TabularToSeriesAdaptor(StandardScaler())),\n",
    "            (\n",
    "                \"forecaster\",\n",
    "                TransformedTargetForecaster(\n",
    "                    [\n",
    "                        (\"log_transformer\", LogTransformer()),\n",
    "                        # (\"deseasonalizer_weekly\", Deseasonalizer(sp=24*7, model=\"additive\")),\n",
    "                        (\n",
    "                            \"forecast\",\n",
    "                            make_reduction(\n",
    "                                GradientBoostingRegressor(n_estimators=200),\n",
    "                                window_length=24,\n",
    "                                strategy=\"direct\",\n",
    "                            ),\n",
    "                        ),\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return pipe\n",
    "\n",
    "\n",
    "def initialize_hist_forecaster():\n",
    "    deseasonalizer_daily = Deseasonalizer(sp=24, model=\"additive\")\n",
    "    pipe = ForecastingPipeline(\n",
    "        steps=[\n",
    "            (\"standardize\", TabularToSeriesAdaptor(StandardScaler())),\n",
    "            (\n",
    "                \"forecaster\",\n",
    "                TransformedTargetForecaster(\n",
    "                    [\n",
    "                        (\"log_transformer\", LogTransformer()),\n",
    "                        # (\"deseasonalizer_weekly\", Deseasonalizer(sp=24*7, model=\"additive\")),\n",
    "                        (\n",
    "                            \"forecast\",\n",
    "                            make_reduction(\n",
    "                                HistGradientBoostingRegressor(),\n",
    "                                window_length=24,\n",
    "                                strategy=\"direct\",\n",
    "                            ),\n",
    "                        ),\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return pipe\n",
    "\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "\n",
    "def initialize_cat_forecaster():\n",
    "    pipe = ForecastingPipeline(\n",
    "        steps=[\n",
    "            (\"standardize\", TabularToSeriesAdaptor(StandardScaler())),\n",
    "            (\n",
    "                \"forecaster\",\n",
    "                TransformedTargetForecaster(\n",
    "                    [\n",
    "                        (\"log_transformer\", LogTransformer()),\n",
    "                        (\n",
    "                            \"forecast\",\n",
    "                            make_reduction(\n",
    "                                CatBoostRegressor(verbose=0, n_estimators=100),\n",
    "                                window_length=24,\n",
    "                                strategy=\"direct\",\n",
    "                            ),\n",
    "                        ),\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return pipe\n",
    "\n",
    "\n",
    "def initialize_lgbm_forecaster():\n",
    "    pipe = ForecastingPipeline(\n",
    "        steps=[\n",
    "            (\"standardize\", TabularToSeriesAdaptor(StandardScaler())),\n",
    "            (\n",
    "                \"forecaster\",\n",
    "                TransformedTargetForecaster(\n",
    "                    [\n",
    "                        (\"log_transformer\", LogTransformer()),\n",
    "                        (\n",
    "                            \"forecast\",\n",
    "                            make_reduction(\n",
    "                                LGBMRegressor(),\n",
    "                                window_length=24,\n",
    "                                strategy=\"direct\",\n",
    "                            ),\n",
    "                        ),\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return pipe\n",
    "\n",
    "\n",
    "def initialize_xgb_forecaster():\n",
    "    pipe = ForecastingPipeline(\n",
    "        steps=[\n",
    "            (\"standardize\", TabularToSeriesAdaptor(StandardScaler())),\n",
    "            (\n",
    "                \"forecaster\",\n",
    "                TransformedTargetForecaster(\n",
    "                    [\n",
    "                        (\"log_transformer\", LogTransformer()),\n",
    "                        (\n",
    "                            \"forecast\",\n",
    "                            make_reduction(\n",
    "                                XGBRegressor(objective=\"reg:squarederror\"),\n",
    "                                window_length=24,\n",
    "                                strategy=\"direct\",\n",
    "                            ),\n",
    "                        ),\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return pipe\n",
    "\n",
    "\n",
    "def initialize_ets_forecaster():\n",
    "    deseasonalizer_daily = Deseasonalizer(sp=24, model=\"additive\")\n",
    "    pipe = TransformedTargetForecaster(\n",
    "        [\n",
    "            (\"log_transformer\", LogTransformer()),\n",
    "            # (\"deseasonalizer_weekly\", Deseasonalizer(sp=24*7, model=\"additive\")),\n",
    "            (\n",
    "                \"forecast\",\n",
    "                make_reduction(\n",
    "                    AutoETS(auto=True, sp=24, n_jobs=-1),\n",
    "                    window_length=24,\n",
    "                    strategy=\"direct\",\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rkris\\miniconda3\\envs\\slalomenv\\Lib\\site-packages\\sktime\\forecasting\\compose\\_reduce.py:1480: UserWarning: The `scitype` of the given `estimator` cannot be inferred. Assuming \"tabular-regressor\" = scikit-learn regressor interface. If this warning is followed by an unexpected exception, please consider report as a bug on the sktime issue tracker.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "arima_pipeline = initialize_arima_forecaster()\n",
    "elasticnet_pipeline = initialize_elasticnet_forecaster()\n",
    "rf_pipeline = initialize_rf_forecaster()\n",
    "gb_pipeline = initialize_gb_forecaster()\n",
    "hist_pipeline = initialize_hist_forecaster()\n",
    "cat_pipeline = initialize_cat_forecaster()\n",
    "lgbm_pipeline = initialize_lgbm_forecaster()\n",
    "xgb_pipeline = initialize_xgb_forecaster()\n",
    "ets_pipeline = initialize_ets_forecaster()\n",
    "\n",
    "\n",
    "forecasting_models = {\n",
    "    \"elasticnet_pipeline\": elasticnet_pipeline,\n",
    "    \"rf_pipeline\": rf_pipeline,\n",
    "    \"gb_pipeline\": gb_pipeline,\n",
    "    \"hist_pipeline\": hist_pipeline,\n",
    "    \"ets_pipeline\": ets_pipeline,\n",
    "    \"arima_pipeline\": arima_pipeline,\n",
    "    \"cat_pipeline\": cat_pipeline,\n",
    "    \"lgbm_pipeline\": lgbm_pipeline,\n",
    "    \"xgb_pipeline\": xgb_pipeline,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols =  ['ail', 'gas_price', 'gas_tng', 'coal_tng',\n",
    "       'wind_tng', 'solar_tng', 'hydro_tng', 'storage_tng', 'other_tng',\n",
    "       'gas_avail', 'dual_fuel_avail', 'coal_avail', 'wind_avail',\n",
    "       'solar_avail', 'hydro_avail', 'storage_avail', 'other_avail',\n",
    "       'gas_reserve_margin', 'coal_reserve_margin', 'wind_reserve_margin',\n",
    "       'solar_reserve_margin', 'hydro_reserve_margin',\n",
    "       'storage_reserve_margin', 'other_reserve_margin', 'total_tng',\n",
    "       'total_avail', 'gas_supply_mix', 'dual_fuel_supply_mix',\n",
    "       'coal_supply_mix', 'wind_supply_mix', 'solar_supply_mix',\n",
    "       'hydro_supply_mix', 'storage_supply_mix', 'other_supply_mix',\n",
    "       'total_reserve_margin', 'relative_gas_reserve', 'demand_supply_ratio',\n",
    "       'avail_gen_ratio', 'fossil_fuel_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_set_selected_cols =  ['ail', 'gas_price', 'gas_tng',\n",
    "       'wind_tng', 'solar_tng', 'hydro_tng', 'wind_avail',\n",
    "       'solar_avail', 'hydro_avail', 'storage_avail', 'other_avail',\n",
    "       'gas_reserve_margin', 'wind_reserve_margin',\n",
    "       'solar_reserve_margin', 'hydro_reserve_margin',\n",
    "       'storage_reserve_margin', 'other_reserve_margin', 'total_tng',\n",
    "       'total_avail', 'gas_supply_mix', 'wind_supply_mix', \n",
    "       'total_reserve_margin', 'demand_supply_ratio',\n",
    "       'avail_gen_ratio', 'fossil_fuel_ratio']\n",
    "\n",
    "subset_small = ['ail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_old_df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/slalom-ubc-mds/Power-Price-Prediction/main/data/processed/supply_load_price.csv\",\n",
    "    parse_dates=[\"Date (MST)\"],\n",
    "    index_col=\"Date (MST)\",\n",
    ")\n",
    "\n",
    "# select only the month of January, 2022\n",
    "price_old_df = price_old_df.loc[\"2023-01-01\":\"2023-01-31\", subset_small+[\"price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_old_df = price_old_df.sort_values(by=\"Date (MST)\")\n",
    "price_old_df = price_old_df.asfreq(\"H\")\n",
    "\n",
    "y = price_old_df[\"price\"]\n",
    "X = price_old_df[subset_small]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds = 34\n"
     ]
    }
   ],
   "source": [
    "cv = ExpandingWindowSplitter(\n",
    "    initial_window=int(len(X) * 0.94), step_length=1, fh=np.arange(1, 13)\n",
    ")\n",
    "\n",
    "n_splits = cv.get_n_splits(y)\n",
    "print(f\"Number of Folds = {n_splits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sktime.utils.plotting import plot_windows, get_windows\n",
    "# train_windows, test_windows = get_windows(y, cv)\n",
    "# plot_windows(y, train_windows, test_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasticnet_pipeline\n",
      "rf_pipeline\n",
      "gb_pipeline\n",
      "hist_pipeline\n",
      "cat_pipeline\n",
      "lgbm_pipeline\n",
      "xgb_pipeline\n"
     ]
    }
   ],
   "source": [
    "from sktime.forecasting.model_evaluation import evaluate\n",
    "from sktime.performance_metrics.forecasting import MeanSquaredScaledError, MeanSquaredError\n",
    "\n",
    "list_models = [\"elasticnet_pipeline\", \"rf_pipeline\", \"gb_pipeline\", \"hist_pipeline\", \"cat_pipeline\", \"lgbm_pipeline\", \"xgb_pipeline\"]\n",
    "\n",
    "rmse_cv_results = []\n",
    "rmse_cv_std = []\n",
    "for i in list_models:\n",
    "    print(i)\n",
    "    results = evaluate(\n",
    "        forecaster=forecasting_models[i],\n",
    "        y=y,\n",
    "        X=X,\n",
    "        cv=cv,\n",
    "        strategy=\"refit\",\n",
    "        return_data=True,\n",
    "        scoring=MeanSquaredError(square_root=True),\n",
    "        backend=\"loky\",\n",
    "        error_score='raise'\n",
    "    )\n",
    "    \n",
    "    rmse = results[\"test_MeanSquaredError\"].mean()\n",
    "    rmse_std = results[\"test_MeanSquaredError\"].std()\n",
    "    rmse_cv_results.append(rmse)\n",
    "    rmse_cv_std.append(rmse_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE_CV</th>\n",
       "      <th>RMSE_CV_STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elasticnet_pipeline</td>\n",
       "      <td>43.149016</td>\n",
       "      <td>14.476646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat_pipeline</td>\n",
       "      <td>43.795019</td>\n",
       "      <td>16.037121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rf_pipeline</td>\n",
       "      <td>43.875671</td>\n",
       "      <td>14.703196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lgbm_pipeline</td>\n",
       "      <td>44.911613</td>\n",
       "      <td>17.147326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hist_pipeline</td>\n",
       "      <td>45.174434</td>\n",
       "      <td>17.086321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xgb_pipeline</td>\n",
       "      <td>45.787849</td>\n",
       "      <td>17.516343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gb_pipeline</td>\n",
       "      <td>46.889125</td>\n",
       "      <td>16.422389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model    RMSE_CV  RMSE_CV_STD\n",
       "0  elasticnet_pipeline  43.149016    14.476646\n",
       "4         cat_pipeline  43.795019    16.037121\n",
       "1          rf_pipeline  43.875671    14.703196\n",
       "5        lgbm_pipeline  44.911613    17.147326\n",
       "3        hist_pipeline  45.174434    17.086321\n",
       "6         xgb_pipeline  45.787849    17.516343\n",
       "2          gb_pipeline  46.889125    16.422389"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_cv_results_df = pd.DataFrame(\n",
    "    {\"Model\": list_models, \"RMSE_CV\": rmse_cv_results, \"RMSE_CV_STD\": rmse_cv_std}\n",
    ").sort_values(by=[\"RMSE_CV\"])\n",
    "rmse_cv_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_old_df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/slalom-ubc-mds/Power-Price-Prediction/main/data/processed/supply_load_price.csv\",\n",
    "    parse_dates=[\"Date (MST)\"],\n",
    "    index_col=\"Date (MST)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = price_old_df.loc[\"2023-01-01\":\"2023-01-31\", subset_small+[\"price\"]]\n",
    "test = price_old_df.loc[\"2023-02-01\":\"2023-02-02\", subset_small+[\"price\"]]\n",
    "train = train.sort_values(by=\"Date (MST)\")\n",
    "train = train.asfreq(\"H\")\n",
    "test = test.sort_values(by=\"Date (MST)\")\n",
    "test = test.asfreq(\"H\")\n",
    "X_train = train[subset_small]\n",
    "y_train = train[\"price\"]\n",
    "X_test = test[subset_small]\n",
    "y_test = test[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasticnet_pipeline\n",
      "31.92572748521333\n",
      "rf_pipeline\n",
      "28.94956001959079\n",
      "gb_pipeline\n",
      "28.886167907523856\n",
      "hist_pipeline\n",
      "39.873682918702166\n",
      "cat_pipeline\n",
      "11.687987042851185\n",
      "lgbm_pipeline\n",
      "27.136643860790493\n",
      "xgb_pipeline\n",
      "21.49555518196534\n"
     ]
    }
   ],
   "source": [
    "# fit and predict for all models\n",
    "fh = np.arange(1, 13)\n",
    "for i in list_models:\n",
    "    print(i)\n",
    "    forecasting_models[i].fit(y_train, X_train, fh=fh)\n",
    "    y_pred = forecasting_models[i].predict(fh, X_train.tail(1))\n",
    "    # get rmse between y_pred and y_test[:12]\n",
    "    rmse = mean_squared_error(y_test[:12], y_pred, squared=False)\n",
    "    print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = evaluate(\n",
    "        forecaster=forecasting_models['elasticnet_pipeline'],\n",
    "        y=y,\n",
    "        X=X,\n",
    "        cv=cv,\n",
    "        strategy=\"refit\",\n",
    "        return_data=True,\n",
    "        scoring=MeanSquaredError(square_root=True),\n",
    "        backend=\"loky\",\n",
    "        error_score='raise'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.83163811677588"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sktime.performance_metrics.forecasting import MeanSquaredScaledError, MeanSquaredError\n",
    "y_train = np.array([5, 0.5, 4, 6, 3, 5, 2])\n",
    "y_true = np.array([3, -0.5, 100, 7, 2])\n",
    "y_pred = np.array([2.5, 0.0, 2, 8, 1.25])\n",
    "rmsse = MeanSquaredError(square_root=True)\n",
    "rmsse(y_true, y_pred, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.83163811677588"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_true, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train = np.array([[0.5, 1], [-1, 1], [7, -6]])\n",
    "y_true = np.array([[0.5, 1], [-1, 1], [7, -6]])\n",
    "y_pred = np.array([[0, 2], [-1, 2], [8, -5]])\n",
    "rmsse(y_true, y_pred, y_train=y_train)\n",
    "\n",
    "rmsse = MeanSquaredScaledError(multioutput='raw_values', square_root=True)\n",
    "rmsse(y_true, y_pred, y_train=y_train)\n",
    "\n",
    "rmsse = MeanSquaredScaledError(multioutput=[0.3, 0.7], square_root=True)\n",
    "rmsse(y_true, y_pred, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# def create_lagged_columns(X, lag_range=24):\n",
    "#     lagged_names = []\n",
    "\n",
    "#     for col in X:\n",
    "#         for lag in range(1, lag_range + 1):\n",
    "#             lagged_names.append(f\"{col}_lag{lag}\")\n",
    "\n",
    "#     return lagged_names\n",
    "\n",
    "# l = create_lagged_columns(['price'] + X.columns.values.tolist(), lag_range=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_pipeline.fit(y_train, X_train, fh=ForecastingHorizon(np.arange(1, 13)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({'Coefficient': rf_pipeline.forecaster_.forecaster_.estimators_[0].feature_importances_, 'Label': l}).sort_values(by=['Coefficient'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({'Coefficient': rf_pipeline.forecaster_.forecaster_.estimators_[1].feature_importances_, 'Label': l}).sort_values(by=['Coefficient'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({'Coefficient': rf_pipeline.forecaster_.forecaster_.estimators_[2].feature_importances_, 'Label': l}).sort_values(by=['Coefficient'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({'Coefficient': rf_pipeline.forecaster_.forecaster_.estimators_[3].feature_importances_, 'Label': l}).sort_values(by=['Coefficient'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({'Coefficient': rf_pipeline.forecaster_.forecaster_.estimators_[4].feature_importances_, 'Label': l}).sort_values(by=['Coefficient'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({'Coefficient': rf_pipeline.forecaster_.forecaster_.estimators_[5].feature_importances_, 'Label': l}).sort_values(by=['Coefficient'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({'Coefficient': rf_pipeline.forecaster_.forecaster_.estimators_[6].feature_importances_, 'Label': l}).sort_values(by=['Coefficient'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({'Coefficient': rf_pipeline.forecaster_.forecaster_.estimators_[7].feature_importances_, 'Label': l}).sort_values(by=['Coefficient'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({'Coefficient': rf_pipeline.forecaster_.forecaster_.estimators_[8].feature_importances_, 'Label': l}).sort_values(by=['Coefficient'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({'Coefficient': rf_pipeline.forecaster_.forecaster_.estimators_[9].feature_importances_, 'Label': l}).sort_values(by=['Coefficient'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({'Coefficient': rf_pipeline.forecaster_.forecaster_.estimators_[10].feature_importances_, 'Label': l}).sort_values(by=['Coefficient'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({'Coefficient': rf_pipeline.forecaster_.forecaster_.estimators_[11].feature_importances_, 'Label': l}).sort_values(by=['Coefficient'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elasticnet_pipeline.fit(y_train, X_train, fh=ForecastingHorizon(np.arange(1, 13)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.inspection import permutation_importance\n",
    "# # permutation_importance(elasticnet_pipeline, y_train, X_train, n_repeats=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elasticnet_pipeline._transform(y_train, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elasticnet_pipeline.forecaster_.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elasticnet_pipeline.forecaster_.forecaster_.get_fitted_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coef_df = pd.DataFrame({'Coefficient': elasticnet_pipeline.forecaster_.forecaster_.estimators_[0].coef_, 'Label': l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print top 10 features\n",
    "# coef_df.sort_values(by=['Coefficient'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coef_df_2 = pd.DataFrame({'Coefficient': elasticnet_pipeline.forecaster_.forecaster_.estimators_[1].coef_, 'Label': l})\n",
    "# coef_df_2.sort_values(by=['Coefficient'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coef_df_2 = pd.DataFrame({'Coefficient': elasticnet_pipeline.forecaster_.forecaster_.estimators_[2].coef_, 'Label': l})\n",
    "# coef_df_2.sort_values(by=['Coefficient'], ascending=False).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mds574",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
