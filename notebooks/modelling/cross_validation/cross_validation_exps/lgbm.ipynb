{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sktime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the selected features from the EDA.\n",
    "- Using 'lgbm_pipeline', and 'elasticnet_pipeline'\n",
    "- lgbm scores improved. elasticnet scores worsened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "import numpy as np\n",
    "from sktime.forecasting.arima import ARIMA\n",
    "from sktime.forecasting.compose import TransformedTargetForecaster\n",
    "from sktime.transformations.series.detrend import Deseasonalizer\n",
    "from sktime.forecasting.trend import PolynomialTrendForecaster\n",
    "from sktime.transformations.series.detrend import Detrender\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sktime.forecasting.compose import make_reduction\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import requests\n",
    "from sklearn.ensemble import (\n",
    "    HistGradientBoostingRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    ")\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sktime.forecasting.model_selection import (\n",
    "    ForecastingGridSearchCV,\n",
    "    ExpandingWindowSplitter,\n",
    ")\n",
    "from sktime.forecasting.compose import MultiplexForecaster\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sktime.forecasting.ets import AutoETS\n",
    "from sktime.transformations.series.boxcox import LogTransformer\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sktime.forecasting.compose import ForecastingPipeline\n",
    "from sktime.transformations.series.adapt import TabularToSeriesAdaptor\n",
    "from sktime.transformations.series.boxcox import BoxCoxTransformer\n",
    "from sktime.forecasting.arima import AutoARIMA\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "\n",
    "def initialize_elasticnet_forecaster():\n",
    "    pipe = TransformedTargetForecaster(\n",
    "                    [\n",
    "                        (\n",
    "                            \"forecast\",\n",
    "                            make_reduction(\n",
    "                                ElasticNetCV(n_jobs=-1),\n",
    "                                window_length=24,\n",
    "                                strategy=\"direct\",\n",
    "                            ),\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "    return pipe\n",
    "\n",
    "\n",
    "def initialize_rf_forecaster():\n",
    "    pipe = TransformedTargetForecaster(\n",
    "                    [\n",
    "                        (\n",
    "                            \"forecast\",\n",
    "                            make_reduction(\n",
    "                                RandomForestRegressor(n_estimators=100, n_jobs=-1),\n",
    "                                window_length=24,\n",
    "                                strategy=\"direct\",\n",
    "                            ),\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "    return pipe\n",
    "\n",
    "\n",
    "def initialize_gb_forecaster():\n",
    "    pipe = TransformedTargetForecaster(\n",
    "                    [\n",
    "                        (\n",
    "                            \"forecast\",\n",
    "                            make_reduction(\n",
    "                                GradientBoostingRegressor(n_estimators=200),\n",
    "                                window_length=24,\n",
    "                                strategy=\"direct\",\n",
    "                            ),\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "           \n",
    "    return pipe\n",
    "\n",
    "\n",
    "def initialize_hist_forecaster():\n",
    "    deseasonalizer_daily = Deseasonalizer(sp=24, model=\"additive\")\n",
    "    pipe = TransformedTargetForecaster(\n",
    "                    [\n",
    "                        (\n",
    "                            \"forecast\",\n",
    "                            make_reduction(\n",
    "                                HistGradientBoostingRegressor(),\n",
    "                                window_length=24,\n",
    "                                strategy=\"direct\",\n",
    "                            ),\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "            \n",
    "    return pipe\n",
    "\n",
    "def initialize_cat_forecaster():\n",
    "    pipe = TransformedTargetForecaster(\n",
    "                    [\n",
    "                        (\n",
    "                            \"forecast\",\n",
    "                            make_reduction(\n",
    "                                CatBoostRegressor(verbose=0, n_estimators=100),\n",
    "                                window_length=24,\n",
    "                                strategy=\"direct\",\n",
    "                            ),\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "    return pipe\n",
    "\n",
    "\n",
    "def initialize_lgbm_forecaster():\n",
    "    pipe = TransformedTargetForecaster(\n",
    "                    [\n",
    "                        (\n",
    "                            \"forecast\",\n",
    "                            make_reduction(\n",
    "                                LGBMRegressor(\n",
    "                        learning_rate=best['learning_rate'],\n",
    "                        max_depth=best['max_depth'],\n",
    "                        n_estimators=best['n_estimators'],\n",
    "                        num_leaves=best['num_leaves'],\n",
    "                        min_child_weight=best['min_child_weight'],\n",
    "                        colsample_bytree=best['colsample_bytree'],\n",
    "                        subsample=best['subsample'],\n",
    "                        reg_alpha=best['reg_alpha'],\n",
    "                        reg_lambda=best['reg_lambda'],\n",
    "                    )\n",
    "                                \n",
    "                                window_length=24,\n",
    "                                strategy=\"direct\",\n",
    "                            ),\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "    return pipe\n",
    "\n",
    "\n",
    "def initialize_xgb_forecaster():\n",
    "    pipe = TransformedTargetForecaster(\n",
    "                    [\n",
    "                        (\n",
    "                            \"forecast\",\n",
    "                            make_reduction(\n",
    "                                XGBRegressor(objective=\"reg:squarederror\"),\n",
    "                                window_length=24,\n",
    "                                strategy=\"direct\",\n",
    "                            ),\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticnet_pipeline = initialize_elasticnet_forecaster()\n",
    "rf_pipeline = initialize_rf_forecaster()\n",
    "gb_pipeline = initialize_gb_forecaster()\n",
    "hist_pipeline = initialize_hist_forecaster()\n",
    "cat_pipeline = initialize_cat_forecaster()\n",
    "lgbm_pipeline = initialize_lgbm_forecaster()\n",
    "xgb_pipeline = initialize_xgb_forecaster()\n",
    "\n",
    "\n",
    "forecasting_models = {\n",
    "    \"elasticnet_pipeline\": elasticnet_pipeline,\n",
    "    \"rf_pipeline\": rf_pipeline,\n",
    "    \"gb_pipeline\": gb_pipeline,\n",
    "    \"hist_pipeline\": hist_pipeline,\n",
    "    \"cat_pipeline\": cat_pipeline,\n",
    "    \"lgbm_pipeline\": lgbm_pipeline,\n",
    "    \"xgb_pipeline\": xgb_pipeline,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    \"other_tng\",\n",
    "    \"gas_tng_ratio\",\n",
    "    \"renewable_energy_ratio\",\n",
    "    \"other_avail\",\n",
    "    \"other_reserve_margin\",\n",
    "    \"gas_reserve_margin\",\n",
    "    \"storage_avail\",\n",
    "    \"gas_tng\",\n",
    "    \"hydro_avail\",\n",
    "    \"wind_avail\",\n",
    "    \"other_supply_mix\",\n",
    "    \"renewable_energy_penetration\",\n",
    "    \"gas_price\",\n",
    "    \"gas_supply_mix\",\n",
    "    \"relative_gas_reserve\",\n",
    "    \"load_on_gas_reserve\",\n",
    "    \"gas_cost\",\n",
    "    \"rolling_mean\",\n",
    "    \"rolling_std\",\n",
    "    \"rolling_min\",\n",
    "    \"rolling_max\",\n",
    "    \"rolling_median\",\n",
    "    \"exp_moving_avg\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_old_df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/slalom-ubc-mds/Power-Price-Prediction/main/data/processed/supply_load_price.csv\",\n",
    "    parse_dates=[\"Date (MST)\"],\n",
    "    index_col=\"Date (MST)\",\n",
    ")\n",
    "\n",
    "window = 24\n",
    "price_old_df = price_old_df.sort_values(by=\"Date (MST)\")\n",
    "price_old_df = price_old_df.asfreq(\"H\")\n",
    "\n",
    "price_old_df['rolling_mean'] = price_old_df['price'].rolling(window).mean().rolling(2).mean().shift(-window // 2)\n",
    "price_old_df['rolling_std'] = price_old_df['price'].rolling(window).std().rolling(2).mean().shift(-window // 2)\n",
    "price_old_df['rolling_min'] = price_old_df['price'].rolling(window).min().rolling(2).mean().shift(-window // 2)\n",
    "price_old_df['rolling_max'] = price_old_df['price'].rolling(window).max().rolling(2).mean().shift(-window // 2)\n",
    "price_old_df['rolling_median'] = price_old_df['price'].rolling(window).median().rolling(2).mean().shift(-window // 2)\n",
    "price_old_df['exp_moving_avg'] = price_old_df['price'].ewm(span=24).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_old_df_filtered = price_old_df.loc[\"2022-12-01\":\"2023-03-28\", selected_features + [\"price\"]]\n",
    "\n",
    "y = price_old_df_filtered[\"price\"]\n",
    "X = price_old_df_filtered[selected_features]\n",
    "\n",
    "# # scale ratios to percentages\n",
    "X[\"gas_supply_mix\"] = X[\"gas_supply_mix\"] * 100\n",
    "X[\"other_supply_mix\"] = X[\"other_supply_mix\"] * 100\n",
    "X['gas_reserve_margin'] = X['gas_reserve_margin'] * 100\n",
    "X['other_reserve_margin'] = X['other_reserve_margin'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds = 23\n"
     ]
    }
   ],
   "source": [
    "cv = ExpandingWindowSplitter(\n",
    "    initial_window=int(len(X) * 0.9), step_length=12, fh=np.arange(1, 13)\n",
    ")\n",
    "\n",
    "n_splits = cv.get_n_splits(y)\n",
    "print(f\"Number of Folds = {n_splits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-422538f4-4434-4ee7-8477-f79499df269c {color: black;background-color: white;}#sk-422538f4-4434-4ee7-8477-f79499df269c pre{padding: 0;}#sk-422538f4-4434-4ee7-8477-f79499df269c div.sk-toggleable {background-color: white;}#sk-422538f4-4434-4ee7-8477-f79499df269c label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-422538f4-4434-4ee7-8477-f79499df269c label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-422538f4-4434-4ee7-8477-f79499df269c label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-422538f4-4434-4ee7-8477-f79499df269c div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-422538f4-4434-4ee7-8477-f79499df269c div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-422538f4-4434-4ee7-8477-f79499df269c div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-422538f4-4434-4ee7-8477-f79499df269c input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-422538f4-4434-4ee7-8477-f79499df269c input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-422538f4-4434-4ee7-8477-f79499df269c div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-422538f4-4434-4ee7-8477-f79499df269c div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-422538f4-4434-4ee7-8477-f79499df269c input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-422538f4-4434-4ee7-8477-f79499df269c div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-422538f4-4434-4ee7-8477-f79499df269c div.sk-estimator:hover {background-color: #d4ebff;}#sk-422538f4-4434-4ee7-8477-f79499df269c div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-422538f4-4434-4ee7-8477-f79499df269c div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-422538f4-4434-4ee7-8477-f79499df269c div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-422538f4-4434-4ee7-8477-f79499df269c div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-422538f4-4434-4ee7-8477-f79499df269c div.sk-item {z-index: 1;}#sk-422538f4-4434-4ee7-8477-f79499df269c div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-422538f4-4434-4ee7-8477-f79499df269c div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-422538f4-4434-4ee7-8477-f79499df269c div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-422538f4-4434-4ee7-8477-f79499df269c div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-422538f4-4434-4ee7-8477-f79499df269c div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-422538f4-4434-4ee7-8477-f79499df269c div.sk-parallel-item:only-child::after {width: 0;}#sk-422538f4-4434-4ee7-8477-f79499df269c div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-422538f4-4434-4ee7-8477-f79499df269c div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-422538f4-4434-4ee7-8477-f79499df269c div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-422538f4-4434-4ee7-8477-f79499df269c div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-422538f4-4434-4ee7-8477-f79499df269c div.sk-text-repr-fallback {display: none;}</style><div id='sk-422538f4-4434-4ee7-8477-f79499df269c' class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TransformedTargetForecaster(steps=[(&#x27;forecast&#x27;,\n",
       "                                    DirectTabularRegressionForecaster(estimator=LGBMRegressor(),\n",
       "                                                                      window_length=24))])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class='sk-label-container'><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=UUID('24aa7175-b040-4aaa-bc3b-9d830ca22a1c') type=\"checkbox\" ><label for=UUID('24aa7175-b040-4aaa-bc3b-9d830ca22a1c') class='sk-toggleable__label sk-toggleable__label-arrow'>TransformedTargetForecaster</label><div class=\"sk-toggleable__content\"><pre>TransformedTargetForecaster(steps=[(&#x27;forecast&#x27;,\n",
       "                                    DirectTabularRegressionForecaster(estimator=LGBMRegressor(),\n",
       "                                                                      window_length=24))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class='sk-item'><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=UUID('1b339e13-2908-4a40-9f71-d3c28c521b3c') type=\"checkbox\" ><label for=UUID('1b339e13-2908-4a40-9f71-d3c28c521b3c') class='sk-toggleable__label sk-toggleable__label-arrow'>LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "TransformedTargetForecaster(steps=[('forecast',\n",
       "                                    DirectTabularRegressionForecaster(estimator=LGBMRegressor(),\n",
       "                                                                      window_length=24))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasting_models['lgbm_pipeline'].fit(y, X, fh=np.arange(1, 13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'steps': [('forecast',\n",
       "   DirectTabularRegressionForecaster(estimator=LGBMRegressor(), window_length=24))],\n",
       " 'forecast': DirectTabularRegressionForecaster(estimator=LGBMRegressor(), window_length=24),\n",
       " 'forecast__estimator': LGBMRegressor(),\n",
       " 'forecast__pooling': 'local',\n",
       " 'forecast__transformers': None,\n",
       " 'forecast__window_length': 24,\n",
       " 'forecast__windows_identical': True,\n",
       " 'forecast__estimator__boosting_type': 'gbdt',\n",
       " 'forecast__estimator__class_weight': None,\n",
       " 'forecast__estimator__colsample_bytree': 1.0,\n",
       " 'forecast__estimator__importance_type': 'split',\n",
       " 'forecast__estimator__learning_rate': 0.1,\n",
       " 'forecast__estimator__max_depth': -1,\n",
       " 'forecast__estimator__min_child_samples': 20,\n",
       " 'forecast__estimator__min_child_weight': 0.001,\n",
       " 'forecast__estimator__min_split_gain': 0.0,\n",
       " 'forecast__estimator__n_estimators': 100,\n",
       " 'forecast__estimator__n_jobs': -1,\n",
       " 'forecast__estimator__num_leaves': 31,\n",
       " 'forecast__estimator__objective': None,\n",
       " 'forecast__estimator__random_state': None,\n",
       " 'forecast__estimator__reg_alpha': 0.0,\n",
       " 'forecast__estimator__reg_lambda': 0.0,\n",
       " 'forecast__estimator__silent': 'warn',\n",
       " 'forecast__estimator__subsample': 1.0,\n",
       " 'forecast__estimator__subsample_for_bin': 200000,\n",
       " 'forecast__estimator__subsample_freq': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasting_models['lgbm_pipeline'].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def create_lagged_columns(X, lag_range=24):\n",
    "    lagged_names = []\n",
    "    for col in X:\n",
    "        for lag in range(lag_range, 0, -1):\n",
    "            lagged_names.append(f\"{col}_lag{lag}\")\n",
    "    return lagged_names\n",
    "labels = create_lagged_columns(['price'] + X.columns.values.tolist(), lag_range=24)\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_transformed = forecasting_models['lgbm_pipeline'].transform(y)  # does all the trasnformations on y\n",
    "y_enc, X_enc = forecasting_models['lgbm_pipeline'].forecaster_._transform(y_transformed, X)  # TransfomedTargetForecaster does not transform X, only y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_enc = pd.DataFrame(y_enc)\n",
    "y_enc.columns = ['price1', 'price2', 'price3', 'price4','price5', 'price6','price7', 'price8','price9', 'price10', 'price11', 'price12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_enc = pd.DataFrame(X_enc, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [18:55<00:00,  5.68s/trial, best loss: 11631.817632872873]\n",
      "Best:  {'colsample_bytree': 0.7281869913357373, 'learning_rate': 0.08299509553463873, 'max_depth': 20, 'min_child_weight': 0.19733949139352877, 'n_estimators': 3, 'num_leaves': 16, 'reg_alpha': 0.8332138510570211, 'reg_lambda': 0.1975545061747418, 'subsample': 0.8293201208815428}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from hyperopt import hp, tpe, Trials, fmin\n",
    "\n",
    "# Assuming you have a dataframe 'df' with columns 'price', 'demand', 'supply'\n",
    "\n",
    "# Split data into X and y\n",
    "X = X_enc\n",
    "y = y_enc['price1']\n",
    "\n",
    "# Define objective function for Hyperopt optimization\n",
    "def objective(params, n_folds=5):\n",
    "    global X\n",
    "    global y\n",
    "    \n",
    "    model = forecasting_models['lgbm_pipeline'].forecaster_.estimators_[0]\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=n_folds)\n",
    "    scores = []\n",
    "    \n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=50, verbose=False)\n",
    "        y_pred = model.predict(X_test)\n",
    "        scores.append(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Define search space for hyperparameters\n",
    "space = {\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'max_depth': hp.choice('max_depth', range(5, 30)),\n",
    "    'n_estimators': hp.choice('n_estimators', range(20, 205)),\n",
    "    'num_leaves': hp.choice('num_leaves', range(20, 100)),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', np.log(0.001), np.log(10)),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0),\n",
    "    'subsample': hp.uniform('subsample', 0.7, 1.0),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0)\n",
    "}\n",
    "\n",
    "# Run optimization\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=200,\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best: \", best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mds574",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
